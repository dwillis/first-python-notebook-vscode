{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f6ab66-37c2-454a-925e-346931e1c3a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ~~First~~ Fast Python Notebook\n",
    "\n",
    "An accelerated guide to analyzing data with the [Python](https://www.python.org/) programming language and a [Jupyter](https://jupyter.org/) notebook\n",
    "   \n",
    "By [Ben Welsh](https://palewi.re/who-is-ben-welsh/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5946d-3e22-4eff-85a8-f066109c41b0",
   "metadata": {},
   "source": [
    "First developed in 2016, [\"First Python Notebook\"](https://palewi.re/docs/first-python-notebook/) is a tutorial that guides students through a data-driven investigation of money in California politics. It is most commonly taught as a six-hour, in-person class. This document is an abbreviated spinoff intended to be taught online in two to three hours.\n",
    "\n",
    "You will learn just enough of the Python computer programming language to work with the [pandas](https://pandas.pydata.org/) library, a popular open-source tool for analyzing data. The course will teach you how to read, filter, join, group, aggregate and rank structured data by recreating a helicopter accident analysis [published by the Los Angeles Times](https://github.com/datadesk/helicopter-accident-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db188ce8-2e8b-4c48-a7b3-d9d98788e345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is a Jupyter notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6129fc8-71b6-40ed-a8c5-e18f50a5d981",
   "metadata": {},
   "source": [
    "<img src=\"https://palewi.re/docs/first-python-notebook/_static/img/labpreview.webp\" style=\"max-width:640px;\">\n",
    "\n",
    "A [Jupyter](https://jupyter.org/) notebook is a browser-based interface where you can write, run, remix and republish code. It is free software that anyone can install and run.\n",
    "\n",
    "[Scientists](https://nbviewer.jupyter.org/github/robertodealmeida/notebooks/blob/master/earth_day_data_challenge/Analyzing%20whale%20tracks.ipynb), [scholars](https://nbviewer.jupyter.org/github/nealcaren/workshop_2014/blob/master/notebooks/5_Times_API.ipynb), [investors](https://github.com/rsvp/fecon235/blob/master/nb/fred-debt-pop.ipynb) and [corporations](https://netflixtechblog.com/notebook-innovation-591ee3221233) use Jupyter to create and share their research. It is also used by journalists to develop stories and show their work. Examples include:\n",
    "\n",
    "*   [“The Tennis Racket”](https://github.com/BuzzFeedNews/2016-01-tennis-betting-analysis/blob/master/notebooks/tennis-analysis.ipynb) by BuzzFeed and the BBC\n",
    "*   [“Machine bias”](https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb) by ProPublica\n",
    "*   [“As Opioid Crisis Ramped Up, Pills Flowed Into Vermont by the Millions”](https://github.com/asuozzo/arcos-opioid-analysis-vt) by Seven Days\n",
    "*   [More than 35 different notebooks](https://github.com/datadesk/notebooks) published by the Los Angeles Times\n",
    "\n",
    "There are numerous ways to install and configure Jupyter notebooks. This class is taught using [JupyterLite](https://jupyterlite.readthedocs.io/) a lightweight distribution that runs entirely in your web browser. For instructions on how to install a more powerful version on your computer consult [the full edition of \"First Python Notebook.'](https://palewi.re/docs/first-python-notebook/jupyter_desktop.html)\n",
    "\n",
    "Once you have this notebook up and running, you're ready to write Python in a code cell. Do not stress. There is nothing too fancy about it. You can start by just doing a little simple math.\n",
    "\n",
    "Select the box below, then hit the play button in the toolbar above the notebook or hit `SHIFT+ENTER` on your keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c8290-2248-44eb-ac49-c558e16fd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d878e7a-8c26-4ea9-992b-cc306e4c8e1c",
   "metadata": {},
   "source": [
    "There. You have just run your first Python code. You have entered two integers and added them together using the plus sign operator.\n",
    "\n",
    "Not so bad, right? Now try writing in your own math problem in the next cell. Maybe `2+3` or `2+200`. Whatever strikes your fancy. After you've typed it in, hit the play button or `SHIFT+ENTER`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fbe22-81a9-49ba-8e92-d466063f9ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aed7d280-9237-4c24-9f43-ed5b4464a8d8",
   "metadata": {},
   "source": [
    "This to-and-fro of writing Python code in a cell and then running it is the rhythm of working in a notebook. If you get an error after you run a cell, look carefully at your code and see that it exactly matches what’s been written in the example.\n",
    "    \n",
    "Here's an example of a error that I've added intentionally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5381f-2daf-40a7-bfa1-9e0c62ac3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75df45-7b74-4c47-8683-0e8fb69e7898",
   "metadata": {},
   "source": [
    "Don’t worry. Code crashes are a normal part of life for computer programmers. They’re usually caused by small typos that can be quickly corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e530e3a5-85bc-4326-a55d-54dbafc58ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48af4c-0230-4624-accd-81589e0293cc",
   "metadata": {},
   "source": [
    "Over time you will gradually stack cells to organize an analysis that runs from top to bottom. The cells can contain variables, functions and other Python tools.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you’ve never written code before, we recommend <a href=\"https://docs.python.org/3/tutorial/introduction.html\">&quot;An Informal Introduction to Python&quot;</a> and subsequent sections of python.org’s tutorial.</p>\n",
    "</div>\n",
    "\n",
    "A simple example would be storing your number in a variable in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44987e01-120e-4920-9140-8ab5c5ee0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce101254-99ae-4b0a-b062-18324d70e134",
   "metadata": {},
   "source": [
    "Then adding it to another number in the next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3b2e7-07db-4db3-b1b9-6c09ad8ad365",
   "metadata": {},
   "outputs": [],
   "source": [
    "number + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b403eaa-d83e-4819-871f-2e8606936f71",
   "metadata": {},
   "source": [
    "Change the `number` value to 3 and run both cells again. Instead of 5, it should now output 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b8643-b444-4253-b38a-4be2732ddbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f55723-8907-4797-ba39-854a77c6a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223912c-1c04-4c3d-a2b3-4904ee39039b",
   "metadata": {},
   "source": [
    "Now try defining your own numeric variable and doing some math with it. You can name it whatever you want. Want to try some other math operations? The `-` sign does subtraction. Multipication is `*`. Division is `/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19513b-1a01-4287-8e29-4362c4fc590f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "997aa7c1-aa6c-4f5b-a8de-802990e87122",
   "metadata": {},
   "source": [
    "Once you’ve got the hang of making the notebook run, you’re ready to introduce pandas, a powerful Python analysis library that can do a whole lot more than add a few numbers together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a769ba4-a9a9-4c26-bbfd-a14ea202b81a",
   "metadata": {},
   "source": [
    "## What is pandas? \n",
    "  \n",
    "<img src=\"https://palewi.re/docs/first-python-notebook/_static/img/pandas-pypi.png\" style=\"max-width:640px;\">\n",
    "\n",
    "Lucky for us, Python is filled with functions to do almost anything you’d want to do with a programming language: [navigate the web](http://docs.python-requests.org/), [parse data](https://docs.python.org/2/library/csv.html), [interact with a database](http://www.sqlalchemy.org/), [run fancy statistics](https://www.scipy.org/), [build a pretty website](https://www.djangoproject.com/) and [so](https://www.crummy.com/software/BeautifulSoup/) [much](http://www.nltk.org/) [more](https://pillow.readthedocs.io/en/stable/).\n",
    "\n",
    "Creative people have put these tools to work to get a [wide range of things](https://www.python.org/about/success/) done in the academy, the laboratory and even in outer space.\n",
    "\n",
    "Some of those tools are included in a toolbox that comes with the language, known as the standard library. Others have been built by members of Python’s developer community and need to be separately downloaded and installed. One third-party tool that’s important for this class is called [pandas](https://pandas.pydata.org/). Invented by programmers at a [financial investment firm](https://www.aqr.com/), it has become a leading open-source library for accessing and analyzing data.\n",
    "\n",
    "Here’s how to use pandas yourself. Run the following:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9441941-4326-4e9a-850a-c5c175259dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05db38a-f532-4ba6-bd9f-0f7700a2eeb6",
   "metadata": {},
   "source": [
    "If nothing happens, that’s good. It means you have it installed and ready as to use.\n",
    "\n",
    "Since pandas is created by a third party independent from the core Python developers, it may not be available by default if you manually installed Python and Jupyter. It’s available here because JupyterLite, whose developers have curated a list of common utilities to include with their distribution. Consult our [advanced installation guide](https://palewi.re/docs/first-python-notebook/appendix/index.html) if the cell above threw an error.\n",
    "\n",
    "Now let's run the same code again, but with a small addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c5ff8-a7f4-409d-a7e2-550787b1dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81953ecf-f91a-4289-a7ea-b03289767de4",
   "metadata": {},
   "source": [
    "This will alias the pandas library at the shorter variable name of `pd`. This is standard practice in the pandas community. You will frequently see examples of pandas code online using pd as shorthand. It’s not required, but it’s good to get in the habit so that your code will be better understood by other computer programmers.\n",
    "\n",
    "Those two little letters contain dozens of data analysis tools that we’ll use in future lessons. They can import massive data files, compute advanced statistics, filter, sort, rank and do just about anything else you’d want to do.\n",
    "\n",
    "We’ll get to all of that soon enough, but let’s start out with something simple. Let's run some simple stats.\n",
    "\n",
    "## Calculating descriptive statistics\n",
    "\n",
    "Start by making a list of numbers in a new notebook cell. To keep things simple, we'll start with all of the even numbers between zero and ten. Note the variable name I've assigned. Then press play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76408f89-55ed-4996-ac0e-c520c91cb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85362e2b-756e-4f9e-bfa6-550311636793",
   "metadata": {},
   "source": [
    "If you’re a skilled Python programmer, you can do some cool stuff with any list, including run statistics. But if you hand over to pandas instead, you’ll be impressed by how easily you can analyze the data without much computer code.\n",
    "\n",
    "In this case, it’s as simple as converting that plain Python list into what pandas calls a [`Series`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html). Here’s how to make it happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855d3fe-4886-4715-ad7a-38bf0f8852dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f121e7f-7abf-4f00-aae0-cc7dddadee05",
   "metadata": {},
   "source": [
    "Once the data becomes a `Series`, you can immediately run a wide range of <a href=\"https://en.wikipedia.org/wiki/Descriptive_statistics\">descriptive statistics</a>. Let’s try a few. First, let’s sum all the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d433a-5379-4df9-acea-252067ff7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da125e-beac-4b1e-b13a-08d1c264598b",
   "metadata": {},
   "source": [
    "Then find the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62ab11-b0bc-4565-9c3b-ce48d9229414",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8500cb7-657d-4dad-923c-71c13006ebda",
   "metadata": {
    "tags": []
   },
   "source": [
    "The minimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3036dd-b239-4f08-903f-989989c257f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fcf04-09c1-4acd-a924-85cf44e99146",
   "metadata": {},
   "source": [
    "How about the average, which also known as the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cfda5-eb9c-4279-ade2-12df439c3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c00db-188a-407a-ad38-dcf987c6182a",
   "metadata": {},
   "source": [
    "The median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cd26c-a2e3-495f-818d-339b10a91040",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce7ebc-ae19-40a7-b235-9dce865ad33d",
   "metadata": {},
   "source": [
    "The standard deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94eb9e9-a92d-4651-8861-9a40545f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b13286-bc88-43c9-a972-51da525a5cd0",
   "metadata": {},
   "source": [
    "Finally, all of the above, plus a little more about the distribution, in one simple command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aab258-f53c-4e01-9f10-67ed52ffb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb421c5-3519-42f3-a4f1-94d1d285f8c8",
   "metadata": {},
   "source": [
    "Before you move on, go back the `my_list` variable and change the list. Maybe add a few more values. Or switch to odds. Then rerun all the cells above. You'll see all the statistics update to reflect the different dataset.\n",
    "\n",
    "Substitute in a series of 10 million records and your notebook would calculate all the same statistics without you needing to write any more code. Once your data, however large or complex, is imported into pandas, simple statistics become a snap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d5836-d7da-482d-a5f0-b1d96c845269",
   "metadata": {},
   "source": [
    "## Introducing DataFrames\n",
    "    \n",
    "Now it’s time to get our hands on some real data. In 2018, the Los Angeles Times published an investigation headlined, <a href=\"https://www.latimes.com/projects/la-me-robinson-helicopters/\">\"The Robinson R44, the world’s best-selling civilian helicopter, has a long history of deadly crashes\".</a>\n",
    "    \n",
    "It reported that the Robinson R44 led all major models with the highest fatal accident rate from 2006 to 2016. The analysis was <a href=\"https://github.com/datadesk/helicopter-accident-analysis\">published on GitHub</a> as a series of Jupyter notebooks. \n",
    "\n",
    "The analysis was based on two key datasets: \n",
    "   \n",
    "1. The National Transportation Safety Board's <a href=\"https://www.ntsb.gov/_layouts/ntsb.aviation/index.aspx\">Aviation Accident Database</a>\n",
    "2. The Federal Aviation Administration's <a href=\"https://www.faa.gov/data_research/aviation_data_statistics/general_aviation/\">General Aviation and Part 135 Activity Survey</a>\n",
    "\n",
    "After a significant amount of work gathering and cleaning the source data, the number of accidents for each helicopter model were normalized using the flight hours estimates in the survey. For the purposes of this demonstration, we will read in tidied versions of each file that are ready for analysis.\n",
    "    \n",
    "The data are structured in rows of comma-separated values. This is known as a [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values). It is the most common way you will find data published online.\n",
    "\n",
    "The pandas library is able to read in files from a variety formats, including CSV. In our next cell, we'll use pandas' `read_csv` method to read in `ntsb-accidents.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb4c5c-be44-4b66-ac7d-0eb2eff70d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"ntsb-accidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595fc09-d269-4452-8edc-0d9d4b3bcded",
   "metadata": {},
   "source": [
    "You should see a big table like the one above. It is a DataFrame where pandas has structured the CSV data into rows and columns, just like Excel or other spreadsheet software might.\n",
    "\n",
    "A major advantage of Jupyter over spreadsheets is that rather than manipulating the data through a haphazard series of clicks and keypunches we will be gradually grinding it down using a computer programming script that is transparent and reproducible.\n",
    "\n",
    "In order to do more with your DataFrame, we need to store it so it can be reused in subsequent cells. We can do this by saving in a variable, which is a fancy computer programming word for a named shortcut where we save our work as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eec507-f2f1-4f41-8876-7e23580ea936",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list = pd.read_csv(\"ntsb-accidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4cd4e-308e-4415-8a27-8f0d279c7eca",
   "metadata": {},
   "source": [
    "After you run it, you shouldn’t see anything. That’s a good thing. It means our DataFrame has been saved under the name `accident_list`, which we can now begin interacting with in the cells that follow.\n",
    "\n",
    "We can do this by calling “methods” that pandas makes available to all DataFrames. You may not have known it at the time, but `read_csv` is one of these methods. There are dozens more that can do all sorts of interesting things. Let’s start with some easy ones that analysts use all the time.\n",
    "\n",
    "To preview the first few rows of the dataset, try the <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html\">`head`</a> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff2b46-590e-4b47-8fb5-ed034fad8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f961f8-ec17-48e8-99fa-27198993e556",
   "metadata": {},
   "source": [
    "It does the first five by default. If you want a different number, submit it as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bb56e-466b-4399-a3a3-1cd488c5f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ac71f-9a87-4dce-933d-c11438fbfdd6",
   "metadata": {},
   "source": [
    "To get a look at all of the columns and what type of data they store, try the [`info`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c9296-d55b-439c-a692-7929b1e46be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378b483-4e55-4b3d-a6bc-10436f8f7931",
   "metadata": {},
   "source": [
    "Look carefully at the results and you'll see we have 163 fatal accidents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f1387-f380-4be5-9df5-9944fb2238cd",
   "metadata": {},
   "source": [
    "## Inspecting columns\n",
    "\n",
    "To see the contents of a column separate from the rest of the DataFrame, add the column’s name to the DataFrame’s variable following a period. We’ll begin with the `latimes_make_and_model` column, which records the standardized name of the helicopter that crashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa8c96-1ae8-4e86-b8fe-eae3ade27d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.latimes_make_and_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aabf7e-fb8a-4b67-af2b-da22baac22ba",
   "metadata": {},
   "source": [
    "That will list the column out as a `Series`, just like the ones we created from scratch earlier. Just as we did then, you can now start tacking on additional methods that will analyze the contents of the column.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">    \n",
    "    <p>You can also access columns a second way, like this: accident_list['latimes_make_and_model'].</p><p>This method isn’t as pretty, but it’s required if your column has a space in its name, which would break the simpler dot-based method.</p>\n",
    "</div>\n",
    "    \n",
    "In this case, the column is filled with characters. So we don’t want to calculate statistics like the median and average, as we did before.\n",
    "\n",
    "There’s another built-in pandas tool that will total up the frequency of values in a column. The method is called `value_counts` and it’s just as easy to use as sum, min or max. All you need to do it is add a period after the column name and chain it on the tail end of your cell.\n",
    "\n",
    "Run the code and you should see the locations ranked by their number of sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fbaa3-6edf-4854-8c7e-e6806d921d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.latimes_make_and_model.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59c465-9813-48b8-98c0-d926516bda1a",
   "metadata": {},
   "source": [
    "Congratulations, you've made your first finding. With that little line of code, you've calculated an important fact: During the period being studied, the Robinson R44 had more fatal accidents than any other helicopter.\n",
    "    \n",
    "You may notice that even though the result has two columns, pandas did not return a clean-looking table in the same way as `head` did for our DataFrame. That’s because our column, a Series, acts a little bit different than the DataFrame created by `read_csv`.\n",
    "\n",
    "In most instances, if you have an ugly Series generated by a method like `value_counts` and you want to convert it into a pretty DataFram,e you can do so by tacking on the `reset_index` method on the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c601c-09e2-475e-90e7-2aeaae4e51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.latimes_make_and_model.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910f7c0-238e-4a5b-b2ca-c72d69602711",
   "metadata": {},
   "source": [
    "Why does `Series` behave differently than a dataframe? Why does `reset_index` have such a weird name?\n",
    "\n",
    "Like so much in computer programming, the answer is simply, “because the people who created the library said so.” It’s important to learn that all open-source programming tools are made by humans, and humans have their quirks. Over time you’ll see pandas has more than a few.\n",
    "\n",
    "As a beginner, you should just accept the oddities and keep moving. As you get more advanced, if there’s something about the system you think could be improved you should consider <a href=\"https://pandas.pydata.org/pandas-docs/stable/development/contributing.html\">contributing</a> to the Python code that operates the library.\n",
    "    \n",
    "Before we move on to the next chapter, here's a challenge. See if you can answer a few more questions a journalist might ask about our dataset. All four of the questions below can be answered using only tricks we've covered thus far. See if you can do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e937a-8104-4fc3-857c-79882379474d",
   "metadata": {},
   "source": [
    "1. What was the total number of fatalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb7ab9-e321-4cbf-b3fe-c1e538422590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb76e010-a376-4b84-9127-4e879a3e253d",
   "metadata": {},
   "source": [
    "2. Which helicopter maker had the most accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01613b77-7990-460f-956a-7b28bf5a531a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e28dabb-6f12-4257-94bb-baf6540b16d3",
   "metadata": {},
   "source": [
    "3. What was the total number of helicopter accidents by year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a5adb-4e8f-4399-bd48-b4afa6c15458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de50c69d-4a4a-491a-9390-ddc128914254",
   "metadata": {},
   "source": [
    "4. What state had the most helicopter accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff63bef-f240-454e-8a5d-18fe4f079553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd7530b6-c16c-44b5-85b1-f7689f797204",
   "metadata": {},
   "source": [
    "## Filtering down the dataset\n",
    "\n",
    "The most common way to filter a DataFrame is to pass an expression as an “index” that can be used to decide which records should be kept and which discarded. You write the expression by combining a column on your DataFrame with an <a href=\"https://en.wikipedia.org/wiki/Operator_(computer_programming)\">“operator”</a> like == or > or < and a value to compare against each row.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>If you are familiar with writing <a href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a> to manipulate databases, pandas’ filtering system is somewhat similar to a WHERE query. The <a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html#where\">official pandas documentation</a> offers direct translations between the two.</p>\n",
    "</div>\n",
    "    \n",
    "Let's try filtering against the `state` field. Save one of the values listed above into a variable. This will allow us to reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124142e-b9da-448d-8b42-35115c0c5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_state = \"IA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09cb284-7783-446c-ab58-1c5b83ad2e13",
   "metadata": {},
   "source": [
    "In the next cell we will ask pandas to narrow down our list of sites to just those that list the location we’re interested in. We will create a filter expression and place it between two flat brackets following the DataFrame we wish to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3cf0f-fe6f-4ffe-a273-f8853a8db957",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list[accident_list.state == my_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee09fc6-4a83-441c-962c-295d2b73fb48",
   "metadata": {},
   "source": [
    "Now we should save the results of that filter into a new variable separate from the full list we imported from the CSV file. Since it includes only the sites for the location we’re interested in let’s call it `my_accidents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86104389-e9ab-499f-b6da-246f1985133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_accidents = accident_list[accident_list.state == my_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484a0bd-eacc-43c0-ae84-a7cb67672abe",
   "metadata": {},
   "source": [
    "To check our work and find out how many committees are left after the filter, let’s run the DataFrame inspection commands we learned earlier.\n",
    "\n",
    "First `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643adbc8-8d71-4f20-9da5-dadb54a1c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480a2a4-6aa6-4b10-99ab-4e150fe20937",
   "metadata": {},
   "source": [
    "Then `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953e98e-0efe-49ac-bf46-0f84118524ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_accidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa783e17-3f62-4972-aea8-5aa94344fb81",
   "metadata": {},
   "source": [
    "## Pivoting with `groupby`\n",
    "\n",
    "The [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) method allows you to group a DataFrame by a column and then calculate a sum, or any other statistic, for each unique value. This functions much like the <a href=\"https://en.wikipedia.org/wiki/Pivot_table\">\"pivot table\"</a> feature found in most spreadsheets.\n",
    "\n",
    "Let's use it to total up the accidents by make and model. You start by passing the field you want to group on to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2911ad-52d9-4fca-9131-7bf1d472422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.groupby(\"latimes_make_and_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4e89d-05ef-442f-a898-90ba4c107ba7",
   "metadata": {},
   "source": [
    "A nice start but you’ll notice you don’t get much back. The data’s been grouped, but we haven’t chosen what to do with it yet. If we wanted the total by model, we would use the `size` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d9e7a-9b4b-4e78-a813-c6eb7a941fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.groupby(\"latimes_make_and_model\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb595ea-1a2f-4074-8a54-0675396c3737",
   "metadata": {},
   "source": [
    "The result is much like `value_counts`, but we're allowed run to all kinds of statistical operations on the group, like `sum`, `mean` and `std`. For instance, we could sum the total number of fatalities for each maker by string that field on the end followed by the statistical method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9b770-a4f2-4134-843d-8d667ee08fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.groupby(\"latimes_make_and_model\").total_fatalities.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd31d6e-d6c5-41f0-adf9-3f3541a0432d",
   "metadata": {},
   "source": [
    "Again our data has come back as an ugly Series. To reformat it as a pretty DataFrame use the `reset_index` method again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e35b3-b67e-4578-aaca-a006a01fd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_list.groupby(\"latimes_make_and_model\").size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8590c7-e4d3-4594-93ed-92f2e358eeed",
   "metadata": {},
   "source": [
    "Now save that as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464c62f-ec7b-45af-b4fa-01abc85f4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_counts = accident_list.groupby(\"latimes_make_and_model\").size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463ea92-ce67-47bb-b236-1101db8ff470",
   "metadata": {},
   "source": [
    "You can clean up the `0` column name assigned by pandas with the `rename` method. The `inplace` option, found on many pandas methods, will save the change to your variable automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c83acc-5313-456a-ac68-30da7d2a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_counts.rename(columns={0: \"accidents\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd38d1-b36d-4d36-851f-db14ab6aa3dd",
   "metadata": {},
   "source": [
    "The result is a DataFrame with the accident totals we'll want to merge with the FAA survey data to calculate rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96fcea9-51ea-4f87-938a-1ac8b40e461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe468b-5d97-4b59-aede-03cf742c90f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merging two dataframes together\n",
    "\n",
    "Next we'll cover how to merge two DataFrames together into a combined table. Before we can do that, we need to read in a second file. We'll pull `faa-survey.csv`, which contains annual estimates of how many hours each type of helicopter was in the air. It was acquired via a Freedom of Information Act request with the FAA.\n",
    "\n",
    "We can rip it in the same was the NTSB accident list, with `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a663a-b266-4b3c-867a-1b7e28ecd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv(\"faa-survey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729aad0-6b1c-43a8-a6e4-426e6b29a595",
   "metadata": {},
   "source": [
    "When joining two tables together, the first step is to look carefully at the columns in each table to find a common column that can be joined. We can do that with the `info` command we learned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea295f3-3f39-466b-af15-445fe8772c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917e775-d606-486d-bbb3-5b8a0d371a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00fce9-7c29-475f-8800-5bf81efda68d",
   "metadata": {},
   "source": [
    "You can see that each table contains the `latimes_make_and_model` column. We can therefore join the two files using the pandas <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\">`merge`</a> method.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><p>If you are familar with traditional databases, you may recognize that the merge method in pandas is similar to SQL’s JOIN statement. If you dig into <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html\">merge’s documentation</a> you will see it has many of the same options.</p></div>\n",
    "\n",
    "Merging two DataFrames is as simple as passing both to pandas built-in `merge` method and specifying which field we’d like to use to connect them together. We will save the result into another new variable, which I'm going to call `merged_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a861a4-7241-4448-81ca-b928286e3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = pd.merge(accident_counts, survey, on=\"latimes_make_and_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82814158-efcf-47ca-ac63-96a5f96ff50c",
   "metadata": {},
   "source": [
    "That new DataFrame can be inspected like any other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fedea-3788-413f-85c1-c5fcc1430e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c12f2c-c888-40ee-9316-afd3b0b5db1b",
   "metadata": {},
   "source": [
    "By looking at the columns you can check how many rows survived the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a378c-1978-4e2f-bd18-90ce8faafa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c6b93-d97b-4230-93db-808f23e50f56",
   "metadata": {},
   "source": [
    "You can also see that the dataframe now contains the same number of records as `accident_totals`. That's good. It means that every record in each dataframe found a match in the other. It's good idea to do a check like this every time you merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf5ff6-64cc-41ee-9374-ddcb76fe3e94",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computing new columns\n",
    "\n",
    "Here's how you can create a new column based on the data in other columns, a process sometimes known as “computing.” In this case, computing can help us calculate a rate by dividing the accidents by flight hours.\n",
    "\n",
    "In many cases, it's no more complicated than combining two series with a mathematical operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690181d2-2f4d-4f1b-92db-5ecacd63c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.accidents / merged_list.total_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3494e-9687-44cb-828c-6b35ac56b842",
   "metadata": {},
   "source": [
    "The resulting series can be added to your dataframe by assigning it to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050dcaf0-4e17-4118-bea2-f294f2b83418",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list['per_hour'] = merged_list.accidents / merged_list.total_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c138f-4f2a-4b36-b9ad-1de2b1a2b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d16e19-1e82-4d6c-92b5-9dabd63778ea",
   "metadata": {},
   "source": [
    "In this case, the result is in scientific notation. As is common when calculating per capita statistics, you can multiple all results by a common number to make the numbers more legible.\n",
    "    \n",
    "That's as easy as tacking on the multiplication at the end of a computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1c29c-9bf3-4d8e-8421-fb887f5b59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list['per_100k_hours'] = (merged_list.accidents / merged_list.total_hours) * 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c4b7b-a821-480f-ac51-45653942e830",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sorting dataframes\n",
    "\n",
    "Another simple but common technique for analyzing data is sorting. This can be useful for ranking the DataFrame to show the highest and lowest members of the group according to a particular column. The <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\">`sort_values`</a> is how pandas does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e160012-886f-45a5-9225-f312b54ecdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.sort_values(\"per_100k_hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477fd22-aa08-4758-afa2-e36ff8d5df26",
   "metadata": {},
   "source": [
    "Note that returns the DataFrame resorted in ascending order from lowest to highest. That is pandas default way of sorting. Here's how you reverse it to show the largest values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5a720-0b17-4ff6-884d-a6c0995ca9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list.sort_values(\"per_100k_hours\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1236d-525a-4f52-a76f-1997246fc458",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further reading\n",
    "\n",
    "Congratulations. With that, we've recreated the analysis published in the Los Angeles Times and covered most of the basic skills necessary to access and analyze data with pandas. If you'd like to learn more, consult <a href=\"https://palewi.re/docs/first-python-notebook/\">the full edition of \"First Python Notebook\"</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
